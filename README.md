# ğŸ§ ETL Spotify â€“ Pipeline de Engenharia de Dados (Raw â†’ Silver â†’ Gold)

## ğŸ“Œ VisÃ£o Geral

Este projeto implementa um pipeline completo de engenharia de dados utilizando a API do Spotify, seguindo o padrÃ£o moderno de camadas Raw, Silver e Gold, com persistÃªncia em PostgreSQL e foco em boas prÃ¡ticas de modelagem, versionamento e escalabilidade.
O objetivo do projeto Ã© demonstrar, na prÃ¡tica, competÃªncias essenciais de um Engenheiro de Dados JÃºnior, indo alÃ©m da simples extraÃ§Ã£o de dados e abordando:

- Arquitetura de dados em camadas;
- PadronizaÃ§Ã£o e qualidade de dados;
- Modelagem dimensional (Star Schema);
- IntegraÃ§Ã£o com APIs REST;
- PersistÃªncia em Data Warehouse relacional;
- OrganizaÃ§Ã£o de projeto e pipelines reexecutÃ¡veis.

---
## ğŸ—ï¸ Arquitetura do Pipeline

```
Spotify API
     â”‚
     â–¼
Extract
     â”‚
     â–¼
RAW (JSON)
     â”‚
     â–¼
Transform
     â”‚
     â–¼
SILVER (CSV estruturado)
     â”‚
     â–¼
Transform
     â”‚
     â–¼
GOLD (DimensÃµes + Fato)
     â”‚
     â–¼
Load
     â”‚
     â–¼
PostgreSQL (schemas silver e gold)
```
## ğŸ§  Tecnologias Utilizadas

- Python 3
- Spotify Web API
- Pandas
- PostgreSQL
- psycopg2
- dotenv
- Arquitetura em camadas (Raw / Silver / Gold)
- Modelagem Dimensional (Star Schema)

## ğŸ§± Estrutura do Projeto

```
etl_spotify/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Dados brutos (JSON)
â”‚   â”œâ”€â”€ silver/         # Dados tratados e normalizados
â”‚   â””â”€â”€ gold/           # Dados analÃ­ticos (dimensÃµes e fatos)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract/
â”‚   â”‚   â””â”€â”€ spotify/
â”‚   â”‚       â””â”€â”€ user_recently_played.py
â”‚   â”‚
â”‚   â”œâ”€â”€ load/
â”‚   â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”‚   â””â”€â”€ raw_loader.py
â”‚   â”‚   â””â”€â”€ db/
â”‚   â”‚       â”œâ”€â”€ load_silver_to_db.py
â”‚   â”‚       â””â”€â”€ load_gold_to_db.py
â”‚   â”‚
â”‚   â”œâ”€â”€ transform/
â”‚   â”‚   â”œâ”€â”€ silver/
â”‚   â”‚   â”‚   â””â”€â”€ silver_recently_played.py
â”‚   â”‚   â””â”€â”€ gold/
â”‚   â”‚       â””â”€â”€ gold_recently_played.py
â”‚   â”‚
â”‚   â””â”€â”€ pipeline.py
â”‚
â”œâ”€â”€ create_tables.py
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```

---

## ğŸ” Etapa 1 - Extract (Spotify API)

- A autenticaÃ§Ã£o utiliza o Authorization Code Flow, padrÃ£o adotado por APIs modernas.
- Consumo do endpoint:
```
  GET /v1/me/player/recently-played
```

- Coleta dos dados de mÃºsicas recentemente tocadas
- Resposta armazenada sem tratamento na camada Raw

### ğŸ“Œ Por que Raw?
A camada Raw preserva os dados originais, permitindo:
- Reprocessamentos
- Auditoria
- ComparaÃ§Ã£o de versÃµes
- CorreÃ§Ã£o de regras sem nova extraÃ§Ã£o

## ğŸ—ƒï¸ Etapa 2 â€” Raw Layer

- Armazenamento dos dados em JSON
- OrganizaÃ§Ã£o por timestamp de carga
- Nenhuma regra de negÃ³cio aplicada

Exemplo:
```
data/raw/recently_played_2025-01-15T10-30-00.json
```

## ğŸ¥ˆ Etapa 3 â€” Silver Layer (Tratamento e PadronizaÃ§Ã£o)

Nesta etapa os dados passam por limpeza, normalizaÃ§Ã£o e padronizaÃ§Ã£o:

### TransformaÃ§Ãµes aplicadas:

- Flatten de estruturas aninhadas
- SeleÃ§Ã£o de colunas relevantes
- ConversÃ£o de tipos (timestamp, boolean, int)
- PadronizaÃ§Ã£o de nomes
- InclusÃ£o de load_date

ğŸ“„ Output:
```
data/silver/recently_played.csv

```
### ğŸ“Œ Objetivo da Silver
Criar uma base:
- ConfiÃ¡vel
- Estruturada
- Pronta para consumo analÃ­tico

## ğŸ¥‡ Etapa 4 â€” Gold Layer (Modelagem Dimensional)

A camada Gold foi construÃ­da seguindo modelagem dimensional (Star Schema).

### ğŸ“ Modelagem
### DimensÃµes

- dim_artist
- dim_album
- dim_track

### Fato

- fact_recently_played

### BenefÃ­cios:

- Melhor performance analÃ­tica
- Clareza semÃ¢ntica
- Facilidade de integraÃ§Ã£o com BI
 - Escalabilidade

### ğŸ“„ Outputs em CSV:
```
data/gold/dim_artist.csv
data/gold/dim_album.csv
data/gold/dim_track.csv
data/gold/fact_recently_played.csv
```
## ğŸ›¢ï¸ Etapa 5 â€” Load no PostgreSQL
### Schemas criados:

- silver
- gold

### EstratÃ©gias utilizadas:

- CREATE SCHEMA IF NOT EXISTS
- CREATE TABLE IF NOT EXISTS

### Chaves primÃ¡rias

- Foreign Keys
- ON CONFLICT DO NOTHING para evitar duplicidade

Exemplo:
```
INSERT INTO silver.recently_played (...)
ON CONFLICT (played_at, track_id) DO NOTHING;
```

## ğŸš€ ExecuÃ§Ã£o do Pipeline
```
python -m src.pipeline
```


O pipeline executa automaticamente:

- Extract + Raw
- Transform Silver
- Transform Gold
- Load Silver â†’ PostgreSQL
- Load Gold â†’ PostgreSQL

## ğŸ§ª Boas PrÃ¡ticas Aplicadas

- SeparaÃ§Ã£o clara de responsabilidades
- CÃ³digo modular e reutilizÃ¡vel
- Uso de variÃ¡veis de ambiente
- Versionamento pronto para produÃ§Ã£o
- Estrutura escalÃ¡vel para novos endpoints
- Pipeline reexecutÃ¡vel (idempotÃªncia)

## âš™ï¸ ConfiguraÃ§Ã£o do Ambiente

### Arquivo `.env`

Na raiz do projeto:

```
SPOTIFY_CLIENT_ID=seu_client_id
SPOTIFY_CLIENT_SECRET=seu_client_secret
SPOTIFY_REDIRECT_URI=http://127.0.0.1:8000/callback
SPOTIFY_SCOPE=user-top-read
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=spotify_dw
POSTGRES_USER=spotify
POSTGRES_PASSWORD=spotify
```

O `REDIRECT_URI` deve ser idÃªntico ao configurado no Spotify Developer Dashboard.

---

## ğŸ§ª Ambiente Virtual

Criar o ambiente virtual:

```
python -m venv .venv
```

Ativar:

Linux / Mac:
```
source .venv/bin/activate
```

Windows:
```
.venv\Scripts\activate
```

---

## ğŸ“¦ InstalaÃ§Ã£o das DependÃªncias

```
pip install flask requests python-dotenv
```

---

## â–¶ï¸ ExecuÃ§Ã£o da AutenticaÃ§Ã£o

A partir da pasta `src/auth`:

```
python app.py
```

Acesse:

```
http://127.0.0.1:8000
```

ApÃ³s a autenticaÃ§Ã£o, o arquivo `token.json` serÃ¡ criado.

---

## ğŸ“¥ ExtraÃ§Ã£o de Dados

Endpoint utilizado:

```
GET /v1/me/top/artists
```

ImplementaÃ§Ã£o:

```
src/extract/user_top_artists.py
```

O retorno da API Ã© um JSON contendo, entre outros campos:

- Nome do artista  
- Popularidade  
- NÃºmero de seguidores  
- GÃªneros musicais  

---

## ğŸ¯ CompetÃªncias Demonstradas

- âœ” Engenharia de Dados
- âœ” Arquitetura em camadas
- âœ” Consumo de APIs REST
- âœ” Modelagem Dimensional
- âœ” SQL e PostgreSQL
- âœ” Python para ETL
âœ” OrganizaÃ§Ã£o de projetos de dados
âœ” Pensamento analÃ­tico e escalÃ¡vel

## ğŸ“ˆ PrÃ³ximos Passos (Roadmap)

- Incrementar carga incremental (watermark)
- Adicionar testes de qualidade de dados
- OrquestraÃ§Ã£o com Airflow
- Deploy em cloud (AWS / GCP / Azure)
- Camada de mÃ©tricas para BI (Power BI)

## ğŸ‘¨â€ğŸ’» Sobre o Autor

### Jackson Nascimento - Engenheiro de Dados em formaÃ§Ã£o | BI | Analytics


Projeto desenvolvido com foco em aprendizado real de engenharia de dados, indo alÃ©m de tutoriais e demonstrando capacidade de estruturar pipelines prÃ³ximos ao cenÃ¡rio profissional.

#### ğŸ”— LinkedIn: https://www.linkedin.com/in/jackson10/

# ğŸ§ ETL Spotify Cloud â€“ Pipeline End-to-End (AWS S3 & RDS)

## ğŸ“Œ VisÃ£o Geral

Este projeto implementa um pipeline de dados 100% em nuvem utilizando a API do Spotify. A arquitetura segue o padrÃ£o Medallion (Raw â†’ Silver â†’ Gold), utilizando serviÃ§os da AWS para armazenamento e persistÃªncia.

O diferencial deste projeto Ã© a transiÃ§Ã£o de um ambiente local para uma infraestrutura escalÃ¡vel, focando em:
- Data Lake com AWS S3.
- Data Warehouse com AWS RDS (PostgreSQL).
- Processamento Incremental (IdempotÃªncia).
- Modelagem Dimensional (Star Schema).

---
## ğŸ—ï¸ Arquitetura do Pipeline

```mermaid
graph TD
    API[Spotify API] -->|Extract| P_RAW[Python: raw_loader]
    P_RAW -->|Upload| S3_RAW(S3: Layer Raw)
    
    S3_RAW -->|Read| P_SILVER[Python: run_silver]
    P_SILVER -->|Save CSV| S3_SILVER(S3: Layer Silver)
    P_SILVER -->|to_sql| RDS_SILVER[(RDS: Schema silver)]
    
    S3_SILVER -->|Read| P_GOLD[Python: run_gold]
    P_GOLD -->|Save CSVs| S3_GOLD(S3: Layer Gold)
    P_GOLD -->|to_sql| RDS_GOLD[(RDS: Schema gold)]

    style API fill:#1DB954,color:#fff
    style RDS_SILVER fill:#336699,color:#fff
    style RDS_GOLD fill:#336699,color:#fff
    style S3_RAW fill:#ff9900,color:#fff
    style S3_SILVER fill:#ff9900,color:#fff
    style S3_GOLD fill:#ff9900,color:#fff
```
## ğŸ§  Tecnologias Utilizadas

- Linguagem: Python 3.11

- Cloud (AWS): S3 (Storage) e RDS (Managed PostgreSQL)

- Bibliotecas: - Pandas (TransformaÃ§Ã£o)

- Boto3 (IntegraÃ§Ã£o AWS S3)

- SQLAlchemy (ORM e ConexÃ£o com Banco)

- Spotipy / Requests (Consumo de API)

- Modelagem: Arquitetura Medallion e Star Schema.

## ğŸ§± Estrutura do Projeto

```
etl_spotify/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract/            # Captura de dados da API
â”‚   â”œâ”€â”€ load/
â”‚   â”‚   â”œâ”€â”€ raw/            # IngestÃ£o para S3 Raw
â”‚   â”‚   â””â”€â”€ db/             # Scripts de criaÃ§Ã£o de schemas/tabelas
â”‚   â”œâ”€â”€ transform/
â”‚   â”‚   â”œâ”€â”€ silver/         # Limpeza e ConsolidaÃ§Ã£o (S3 + RDS)
â”‚   â”‚   â””â”€â”€ gold/           # Modelagem Star Schema (S3 + RDS)
â”‚   â””â”€â”€ pipeline.py         # Orquestrador do fluxo completo
â”‚
â”œâ”€â”€ .env                    # VariÃ¡veis de ambiente (AWS/DB)
â”œâ”€â”€ .gitignore              # ProteÃ§Ã£o de credenciais e dados
â””â”€â”€ requirements.txt

```

---

## ğŸ› ï¸ Camadas de Dados

### ğŸ“¥ 1. Camada Raw (S3)

- Origem: Spotify API (/recently-played).

- Formato: JSON Bruto.

- Armazenamento: Salvo no bucket S3 organizado por data de extraÃ§Ã£o (extraction_date=YYYY-MM-DD/).

- Objetivo: Garantir a imutabilidade dos dados originais para reprocessamento.

### ğŸ¥ˆ 2. Camada Silver (S3 + RDS)

- Processamento: O Python lÃª todos os arquivos JSON do S3, limpa, normaliza e remove duplicatas.

- Incremental: A lÃ³gica de merge garante que apenas novas mÃºsicas sejam adicionadas.

- PersistÃªncia: - Arquivo CSV consolidado no S3 Silver.

- Tabela espelho no RDS PostgreSQL (Schema silver).

### ğŸ¥‡ 3. Camada Gold (S3 + RDS)

- Modelagem: TransformaÃ§Ã£o da tabela Ãºnica em um modelo Star Schema.

- Tabelas Geradas: - dim_artist, dim_album, dim_track (DimensÃµes), fact_recently_played (Fato).

- Objetivo: Dados prontos para consumo por ferramentas de BI (Power BI/Tableau) com alta performance de consulta.



## ğŸš€ ExecuÃ§Ã£o do Pipeline
```
python -m src.pipeline
```
#### Fluxo de ExecuÃ§Ã£o:

- Valida infraestrutura no RDS (CriaÃ§Ã£o de Schemas).

- Extrai dados novos do Spotify e envia para S3 Raw.

- Processa a Silver, consolidando o histÃ³rico no S3 e atualizando o banco.

- Processa a Gold, gerando o modelo dimensional no RDS.

## âš™ï¸ ConfiguraÃ§Ã£o do Ambiente (.env)

```
# Spotify
SPOTIFY_CLIENT_ID=...
SPOTIFY_CLIENT_SECRET=...

# AWS
S3_BUCKET_NAME=seu-bucket-spotify
AWS_ACCESS_KEY_ID=...
AWS_SECRET_ACCESS_KEY=...

# RDS / PostgreSQL
DB_HOST=seu-endpoint-rds.aws.com
DB_PORT=5432
DB_NAME=spotify_aws
DB_USER=postgres
DB_PASSWORD=sua_senha
```

## ğŸ§ª Boas PrÃ¡ticas Aplicadas

- SeparaÃ§Ã£o clara de responsabilidades
- CÃ³digo modular e reutilizÃ¡vel
- Uso de variÃ¡veis de ambiente
- Versionamento pronto para produÃ§Ã£o
- Estrutura escalÃ¡vel para novos endpoints
- Pipeline reexecutÃ¡vel (idempotÃªncia)


## ğŸ§ª Ambiente Virtual

Criar o ambiente virtual:

```
python -m venv .venv
```

Ativar:

Linux / Mac:
```
source .venv/bin/activate
```

Windows:
```
.venv\Scripts\activate
```

---

## ğŸ“¦ InstalaÃ§Ã£o das DependÃªncias

```
pip install flask requests python-dotenv
```

---

## ğŸ¯ CompetÃªncias Demonstradas

- âœ” Cloud Computing: Gerenciamento de serviÃ§os AWS (S3 e RDS).
- âœ” Engenharia de Dados: ImplementaÃ§Ã£o de arquitetura Medallion.
- âœ” DevOps/SeguranÃ§a: Uso de .env, .gitignore e boas prÃ¡ticas de credenciais.
- âœ” SQL AvanÃ§ado: ManipulaÃ§Ã£o de Schemas, Constraints (Cascade/Drop) e Modelagem Dimensional.
- âœ” Python: ManipulaÃ§Ã£o de buffers em memÃ³ria (io.StringIO) e integraÃ§Ã£o com APIs.

## ğŸ‘¨â€ğŸ’» Sobre o Autor

### Jackson Nascimento - Engenheiro de Dados em formaÃ§Ã£o | BI | Analytics


Projeto desenvolvido com foco em aprendizado real de engenharia de dados, indo alÃ©m de tutoriais e demonstrando capacidade de estruturar pipelines prÃ³ximos ao cenÃ¡rio profissional.

#### ğŸ”— LinkedIn: https://www.linkedin.com/in/jackson10/
